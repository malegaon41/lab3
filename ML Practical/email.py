# -*- coding: utf-8 -*-
"""email.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14Gr4avacYlTp1v8FZxQ0gp4jd0UFQJLG
"""

# ---------------------------------------------------------
# 1. Import Libraries
# ---------------------------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score, confusion_matrix, precision_score,
    recall_score, f1_score, classification_report
)

# ---------------------------------------------------------
# 2. Load Dataset
# ---------------------------------------------------------
df = pd.read_csv("emails.csv")   # Upload to Colab first

print("Dataset Loaded Successfully")
df.head()

# ---------------------------------------------------------
# 3. Check for Missing Values
# ---------------------------------------------------------
df.isnull().sum()

# ---------------------------------------------------------
# 4. Features & Target
# ---------------------------------------------------------

X = df["text"]           # email content
y = df["spam"]           # 1 = spam, 0 = not spam

print("Features Loaded:", X.shape)
print("Target Loaded:", y.shape)

# ---------------------------------------------------------
# 5. Train / Test Split
# ---------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)

print("Training Size:", X_train.shape)
print("Testing Size:", X_test.shape)

# ---------------------------------------------------------
# 6. TF-IDF Vectorization (robust; handles empty / stopword-only docs)
# ---------------------------------------------------------
import re
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS

# Ensure strings and strip whitespace
X_train = X_train.astype(str).str.strip()
X_test  = X_test.astype(str).str.strip()

# Function: does a document contain any non-stopword token?
def has_meaningful_token(doc):
    # find word tokens (letters/digits/underscore)
    tokens = re.findall(r'\w+', doc.lower())
    # keep tokens that are not stopwords
    tokens = [t for t in tokens if t not in ENGLISH_STOP_WORDS]
    return len(tokens) > 0

# Identify meaningful docs in training set
mask_train = X_train.apply(has_meaningful_token)

# If all training docs were filtered out, raise clear error with guidance
if mask_train.sum() == 0:
    raise ValueError(
        "No training documents contain tokens after removing stop words. "
        "Possible causes: your 'text' column is empty / contains only stopwords / "
        "you converted a wrong column. Check the dataset or reduce stop_words."
    )

# Filter out empty / stopword-only docs from training (and corresponding labels)
num_removed = len(mask_train) - mask_train.sum()
if num_removed > 0:
    print(f"Removed {num_removed} training documents that were empty or stopword-only.")
    X_train = X_train[mask_train].reset_index(drop=True)
    y_train = y_train[mask_train].reset_index(drop=True)
else:
    # reset indices for consistent behaviour
    X_train = X_train.reset_index(drop=True)
    y_train = y_train.reset_index(drop=True)

# For test set: keep them, but convert any truly-empty to empty string (vectorizer will handle rows with no tokens)
X_test = X_test.reset_index(drop=True)

# Create TF-IDF vectorizer.
# Use token_pattern that allows single-letter tokens when necessary.
tfidf = TfidfVectorizer(stop_words='english', max_features=5000, token_pattern=r'(?u)\b\w+\b')

# Fit on cleaned training data and transform
X_train_tfidf = tfidf.fit_transform(X_train)

# Transform test â€” empty test docs will produce zero vectors (allowed)
X_test_tfidf = tfidf.transform(X_test)

print("TF-IDF Transformation Completed Successfully!")
print(f"Training samples (after cleaning): {X_train_tfidf.shape[0]}")
print(f"Features (vocabulary size): {X_train_tfidf.shape[1]}")

# ----------------- Train classifiers and evaluate (drop-in block) -----------------
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    confusion_matrix, accuracy_score, precision_score, recall_score,
    f1_score, classification_report, roc_auc_score
)
import numpy as np
import pandas as pd

# Ensure label arrays are int and indices are aligned
y_train = y_train.astype(int).reset_index(drop=True)
y_test  = y_test.astype(int).reset_index(drop=True)

print("\nShapes:")
print(" X_train_tfidf:", getattr(X_train_tfidf, "shape", None))
print(" X_test_tfidf :", getattr(X_test_tfidf, "shape", None))
print(" y_train      :", y_train.shape)
print(" y_test       :", y_test.shape)

# ----------------- KNN -----------------
print("\nTraining K-Nearest Neighbors (k=5)...")
knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)
knn.fit(X_train_tfidf, y_train)

knn_pred = knn.predict(X_test_tfidf)
knn_prob = None
if hasattr(knn, "predict_proba"):
    try:
        knn_prob = knn.predict_proba(X_test_tfidf)[:, 1]  # may be multiclass -> this picks class index 1
    except Exception:
        knn_prob = None

# Metrics (weighted average works for binary and multiclass)
knn_cm   = confusion_matrix(y_test, knn_pred)
knn_acc  = accuracy_score(y_test, knn_pred)
knn_err  = 1.0 - knn_acc
knn_prec = precision_score(y_test, knn_pred, average='weighted', zero_division=0)
knn_rec  = recall_score(y_test, knn_pred, average='weighted', zero_division=0)
knn_f1   = f1_score(y_test, knn_pred, average='weighted', zero_division=0)
knn_auc  = np.nan
try:
    # only compute AUC when binary (y_test has 2 unique values) and probabilities exist
    if knn_prob is not None and len(np.unique(y_test)) == 2:
        knn_auc = roc_auc_score(y_test, knn_prob)
except Exception:
    knn_auc = np.nan

print("\n=== KNN Results ===")
print("Confusion Matrix:\n", knn_cm)
print(f"Accuracy : {knn_acc:.4f}")
print(f"Error    : {knn_err:.4f}")
print(f"Precision: {knn_prec:.4f}")
print(f"Recall   : {knn_rec:.4f}")
print(f"F1 Score : {knn_f1:.4f}")
if not np.isnan(knn_auc):
    print(f"AUC      : {knn_auc:.4f}")

print("\nKNN Classification Report:")
print(classification_report(y_test, knn_pred, zero_division=0))

# ----------------- SVM -----------------
print("\nTraining Support Vector Machine (linear kernel)...")
svm = SVC(kernel='linear', probability=True, random_state=42)
svm.fit(X_train_tfidf, y_train)

svm_pred = svm.predict(X_test_tfidf)
svm_prob = None
if hasattr(svm, "predict_proba"):
    try:
        svm_prob = svm.predict_proba(X_test_tfidf)[:, 1]
    except Exception:
        svm_prob = None

svm_cm   = confusion_matrix(y_test, svm_pred)
svm_acc  = accuracy_score(y_test, svm_pred)
svm_err  = 1.0 - svm_acc
svm_prec = precision_score(y_test, svm_pred, average='weighted', zero_division=0)
svm_rec  = recall_score(y_test, svm_pred, average='weighted', zero_division=0)
svm_f1   = f1_score(y_test, svm_pred, average='weighted', zero_division=0)
svm_auc  = np.nan
try:
    if svm_prob is not None and len(np.unique(y_test)) == 2:
        svm_auc = roc_auc_score(y_test, svm_prob)
except Exception:
    svm_auc = np.nan

print("\n=== SVM Results ===")
print("Confusion Matrix:\n", svm_cm)
print(f"Accuracy : {svm_acc:.4f}")
print(f"Error    : {svm_err:.4f}")
print(f"Precision: {svm_prec:.4f}")
print(f"Recall   : {svm_rec:.4f}")
print(f"F1 Score : {svm_f1:.4f}")
if not np.isnan(svm_auc):
    print(f"AUC      : {svm_auc:.4f}")

print("\nSVM Classification Report:")
print(classification_report(y_test, svm_pred, zero_division=0))

# ----------------- Summary table -----------------
results_df = pd.DataFrame({
    "Model": ["KNN", "SVM"],
    "Accuracy": [knn_acc, svm_acc],
    "Error": [knn_err, svm_err],
    "Precision": [knn_prec, svm_prec],
    "Recall": [knn_rec, svm_rec],
    "F1": [knn_f1, svm_f1],
    "AUC": [knn_auc, svm_auc]
})
print("\n=== Summary Comparison ===")
print(results_df.round(4))

# Optional: save results
# results_df.to_csv("knn_svm_comparison.csv", index=False)
